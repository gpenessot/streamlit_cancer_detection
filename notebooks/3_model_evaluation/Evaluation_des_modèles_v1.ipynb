{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTDL0ZKYWMqb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join\n",
    "import time\n",
    "\n",
    "import shutil\n",
    "\n",
    "import PIL.Image\n",
    "\n",
    "from tensorflow.math import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, apply_affine_transform\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(21)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IakC0kx8W500",
    "outputId": "b6690ff7-9b2e-4614-bcf0-c565c7425dff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "FOLDER = join(os.getcwd(), \"data/annotated_regions\")\n",
    "FOLDER_0 = join(os.getcwd(), \"data\")\n",
    "FOLDER_SMALL = join(os.getcwd(), \"data/annotated_regions_small\")\n",
    "CSV_FILE = join(os.getcwd(),\"data/train_annotations.csv\")\n",
    "\n",
    "GDRIVE_MOUNT = '/content/drive'\n",
    "GDRIVE_FOLDER = \"MyDrive/DataScientest/DS Project Datas\"\n",
    "FOLDER_MODELS = join(GDRIVE_MOUNT, GDRIVE_FOLDER, \"Modeles\")\n",
    "\n",
    "def download_data(gdrive_folder):\n",
    "  from google.colab import drive\n",
    "  \n",
    "  drive.mount(GDRIVE_MOUNT) \n",
    "\n",
    "  time.sleep(1)\n",
    "  \n",
    "  shutil.unpack_archive(join(GDRIVE_MOUNT,gdrive_folder,\"annotated_regions.zip\"), join(\"content\",FOLDER_0))\n",
    "  shutil.unpack_archive(join(GDRIVE_MOUNT, gdrive_folder,\"annotated_regions_small.zip\"), join(\"content\",FOLDER_SMALL))\n",
    "  shutil.copy(join(GDRIVE_MOUNT, gdrive_folder,\"train_annotations.csv\"), CSV_FILE)\n",
    "\n",
    "## Le dossier DataScientest/DS Project Datas est à la racine de mon Google Drive.\n",
    "download_data(GDRIVE_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzyL59gHBH1A"
   },
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckNnoxbRD43a"
   },
   "outputs": [],
   "source": [
    "def df_test_train_split(images_small = True, classes = 4):\n",
    "\n",
    "  \"\"\"Retourne un df_train et un df_test qui contient les URI vers les images\n",
    "     et les classes associées\n",
    "\n",
    "    Parameters:\n",
    "      images_small : Si True, on utilise les images de taille réduite \n",
    "                     dans le dossier FOLDER_SMALL, sinon on garde les \n",
    "                     images pleine taille du dossier FOLDER\n",
    "      classes : Choix de 4 ou 2 classes (1 vs 2-3-4)\n",
    "                ou \"regression\" si on souhaite réaliser une regression plutot qu'une classification                       \n",
    "\n",
    "    Returns:\n",
    "      df_train, df_test                   \n",
    "  \"\"\"\n",
    "\n",
    "  df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "  if images_small :\n",
    "    folder = FOLDER_SMALL\n",
    "  else:\n",
    "    folder = FOLDER\n",
    "\n",
    "  df[\"filename\"] = folder + \"/\" + df.annotation_id + \".jpeg\"\n",
    "  \n",
    "  if classes == 4:\n",
    "    df['class'] = df['annotation_class'].astype('string')\n",
    "  elif classes == 2:\n",
    "    df[\"class\"] = df.annotation_class.replace([1,2,3],1).astype('string')\n",
    "  elif classes == \"regression\":\n",
    "    df['class'] = df['annotation_class'].astype('float')\n",
    "\n",
    "  df.drop(columns=[\"annotation_id\",\"annotation_class\"], inplace=True)\n",
    "\n",
    "  df_train=df.sample(frac=0.85, random_state=21).copy()\n",
    "  df_test=df.drop(df_train.index).copy()\n",
    "\n",
    "  return df_train, df_test\n",
    "\n",
    "# df_train, df_test = df_test_train_split(images_small = False, classes = 4)\n",
    "# df_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "# Création des générateurs d'images augmentées\n",
    "# Reprend la fonction df_test_train_split précédente, et on fait passer : \n",
    "# - la fonction de préprocessing du CNN utilisé\n",
    "# - les aumgentations souhaitées (soit un dict, soit une fonction)\n",
    "###\n",
    "\n",
    "def get_generators( images_small = True, classes = 4, preprocess_input = None, augmentation_input = None, rescale = 1):\n",
    "\n",
    "  \"\"\"Crée des générateurs d'image d'entrainement, de validation et de test\n",
    "     Les données du générateur d'entrainement sont augmentée\n",
    "\n",
    "    Parameters:\n",
    "      images_small (bool) : Si True, on utilise les images de taille réduite dans le dossier FOLDER_SMALL, sinon on garde les images pleine taille du dossier FOLDER\n",
    "      classes (4,2,\"regression\") : Choix de 4 ou 2 classes (1 vs 2-3-4) ou \"regression\" si on souhaite réaliser une regression plutot qu'une classification\n",
    "      preprocess_input (func) : fonction de preprocessing (pour le cas du transfert learning)\n",
    "      augmentation_input (dict or func) : dict contenant les paramètre à passer à ImageDataGenerator ou fonction d'augmentation de données (qui sera appliquée après preprocess_input)\n",
    "      rescale (float) : ratio de rescale des données d'entrée (surtout pour les CNN custumisés)\n",
    "\n",
    "    Returns:\n",
    "      train_generator, validation_generator, test_generator                  \n",
    "  \"\"\"\n",
    "\n",
    "  if augmentation_input is None:\n",
    "    augmentation = {}\n",
    "    preprocess = preprocess_input\n",
    "  elif callable(augmentation_input):\n",
    "    if preprocess_input is None:\n",
    "      preprocess = augmentation_input\n",
    "    else:\n",
    "      preprocess = lambda x : augmentation_input(preprocess_input(x))\n",
    "    augmentation = {}\n",
    "  else:\n",
    "    preprocess = preprocess_input\n",
    "    augmentation = augmentation_input\n",
    "\n",
    "  train_data_generator = ImageDataGenerator(preprocessing_function=preprocess,\n",
    "                                            **augmentation,                                            \n",
    "                                            fill_mode = \"constant\",\n",
    "                                            cval=255,\n",
    "                                            rescale=rescale,\n",
    "                                            validation_split=0.175)\n",
    "\n",
    "  val_data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                          rescale=rescale,\n",
    "                                          validation_split=0.175)\n",
    "  \n",
    "  test_data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                          rescale=rescale)\n",
    "  \n",
    "  df_train, df_test = df_test_train_split(images_small, classes )\n",
    "\n",
    "  if classes == 2:\n",
    "    class_mode = \"binary\"\n",
    "  elif classes == 4:\n",
    "    class_mode = \"sparse\"\n",
    "  elif classes == \"regression\":\n",
    "    class_mode = \"raw\"\n",
    "\n",
    "  train_generator = train_data_generator.flow_from_dataframe(df_train, \n",
    "                                                            class_mode=class_mode,\n",
    "                                                            subset=\"training\",\n",
    "                                                             batch_size=BATCH_SIZE                                                         \n",
    "                                                            )\n",
    "\n",
    "  validation_generator = val_data_generator.flow_from_dataframe(df_train, \n",
    "                                                            class_mode=class_mode,\n",
    "                                                            subset=\"validation\",\n",
    "                                                             batch_size=BATCH_SIZE                                                            \n",
    "                                                            )\n",
    "\n",
    "  test_generator = test_data_generator.flow_from_dataframe(df_test,\n",
    "                                                          class_mode=class_mode,\n",
    "                                                          shuffle=False,\n",
    "                                                      )\n",
    "  \n",
    "  return train_generator, validation_generator, test_generator\n",
    "\n",
    "\n",
    "def rotate_and_zoom(input_image):\n",
    "  \"\"\"Applique une rotation aléatoire à l'image puis un zoom afin de recadrer sans avoir de \"blanc\" dans les angles\n",
    "\n",
    "    Parameters:\n",
    "      input_image : Image d'entrée\n",
    "      \n",
    "    Returns:\n",
    "      output_image : image après rotation et zoom         \n",
    "  \"\"\"\n",
    "\n",
    "  def ratio_zoom(angle):\n",
    "    t = np.tan(np.deg2rad(np.mod(angle,90)))\n",
    "    return np.sqrt( (1+t**2)/(1+t)**2)\n",
    "  \n",
    "  angle = np.random.uniform(0,360)\n",
    "  \n",
    "  ## On applique la rotation\n",
    "  input_image = apply_affine_transform(input_image, theta=angle)\n",
    "  \n",
    "  ## Puis on zoome\n",
    "  zoom = ratio_zoom(angle)\n",
    "  output_image = apply_affine_transform(input_image, zx=zoom, zy=zoom)\n",
    "\n",
    "  return output_image\n",
    "\n",
    "augmentation_0 = {}\n",
    "\n",
    "augmentation_1 = {\n",
    "    \"width_shift_range\" : 0.1,\n",
    "    \"height_shift_range\" : 0.1,\n",
    "    \"horizontal_flip\" : True,\n",
    "    \"vertical_flip\" : True}\n",
    "\n",
    "augmentation_2 = {\n",
    "    \"rotation_range\" : 90,\n",
    "    \"width_shift_range\" : 0.1,\n",
    "    \"height_shift_range\" : 0.1,\n",
    "    \"zoom_range\"  : 0.1,\n",
    "    \"horizontal_flip\" : True,\n",
    "    \"vertical_flip\" : True}\n",
    "\n",
    "augmentation_3 = rotate_and_zoom\n",
    "# train_generator, validation_generator, test_generator = get_generators( images_small = False, \n",
    "#                                                                        classes = 4, \n",
    "#                                                                        preprocess_input = None, \n",
    "#                                                                        augmentation_input = augmentation_1, \n",
    "#                                                                       )\n",
    "def afficher_images(generators):\n",
    "  plt.figure(figsize=(15,10))\n",
    "\n",
    "  for i, generator in enumerate(generators):\n",
    "    img, label = generator.next()\n",
    "    for j in range(6):\n",
    "      plt.subplot(3,6,i*6 + j +1)\n",
    "      plt.imshow(img[j]/255)\n",
    "      plt.title( label[j])\n",
    "      plt.axis(\"off\")\n",
    "\n",
    "# afficher_images((train_generator, validation_generator, test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bG8zCr3Vl-d"
   },
   "source": [
    "# Entrainements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CSOenzL1Zzq1"
   },
   "outputs": [],
   "source": [
    "###\n",
    "#  Fonction qui compile et entraine le modèle\n",
    "#  Permet de réutiliser le meme code lorsque l'on fait des entrainement avant et après le figeage des couches profondes.\n",
    "###\n",
    "\n",
    "def compile_and_train(model, train_generator, validation_generator,  callbacks, classes = 4, lr = 5e-3, epochs=50):\n",
    "\n",
    "  if classes == \"regression\":\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    def accuracy_reg(y_true, y_pred):\n",
    "      y_pred_round = tf.minimum(3,tf.maximum(0,tf.cast(tf.math.round(y_pred),\"int32\")))\n",
    "      return tf.keras.metrics.binary_accuracy(tf.cast(y_true,\"int32\"), tf.cast(y_pred_round,\"int32\"))\n",
    "\n",
    "    loss = \"mean_squared_error\"\n",
    "    metrics = ['mae', accuracy_reg]\n",
    "  else:\n",
    "    loss=SparseCategoricalCrossentropy()\n",
    "    metrics=['accuracy']\n",
    "    \n",
    "\n",
    "  model.compile(optimizer=Adam(learning_rate=lr), \n",
    "                  loss=loss, \n",
    "                  metrics=metrics)\n",
    "  \n",
    "  history = model.fit(train_generator,\n",
    "                      epochs=epochs, \n",
    "                      workers=-1, \n",
    "                      use_multiprocessing=True,\n",
    "                      validation_data=validation_generator, \n",
    "                      callbacks=callbacks\n",
    "                      )\n",
    "  \n",
    "  return history.history\n",
    "\n",
    "\n",
    "def create_callbacks(nom):\n",
    "  reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                factor=0.3,\n",
    "                                patience=3)\n",
    "\n",
    "  early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                                 patience=8,\n",
    "                                 restore_best_weights=True)\n",
    "\n",
    "  checkpoint_filepath = join(FOLDER_MODELS, f\"{nom}/{nom}-model.h5\")\n",
    "\n",
    "  model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                              save_best_only=True)\n",
    "  \n",
    "  callbacks = [reduce_lr,early_stopping, model_checkpoint_callback]\n",
    "\n",
    "  return callbacks\n",
    "\n",
    "def train_model(model, nom, train_generator, validation_generator, classes = 4, epochs = (50,50), retrain = False, lr = (5e-3, 5e-4)):\n",
    "\n",
    "  callbacks = create_callbacks(nom)\n",
    "\n",
    "  history1 = compile_and_train(model, train_generator, validation_generator,  callbacks,classes = classes, lr = lr[0], epochs=epochs[0])\n",
    "  \n",
    "  df_history = pd.DataFrame(history1)\n",
    "\n",
    "  if retrain:\n",
    "    model.trainable = True\n",
    "    \n",
    "    history2 = compile_and_train(model, train_generator, validation_generator,  callbacks,classes = classes, lr = lr[1], epochs=epochs[1])\n",
    "\n",
    "    df_history = pd.concat([df_history, pd.DataFrame(history2)]).reset_index(drop=True)\n",
    "\n",
    "  df_history.to_csv(join(FOLDER_MODELS, f\"{nom}/{nom}-history.csv\"))\n",
    "  \n",
    "  return df_history\n",
    "\n",
    "\n",
    "# nom = \"EN-small-4-A1\"\n",
    "# history = train_model(model, nom, train_generator, validation_generator, classes=4, 1)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "def plot_history(history, classes = 4):\n",
    "\n",
    "  fig,ax = plt.subplots()\n",
    "  epochs = history.index\n",
    "\n",
    "  if classes == \"regression\":\n",
    "    ax.plot(epochs, history['mae'], 'r', label='Training mae')\n",
    "    ax.plot(epochs, history['val_mae'], 'b', label='Validation mae')\n",
    "  else:\n",
    "    ax.plot(epochs, history['accuracy'], 'r', label='Training accuracy')\n",
    "    ax.plot(epochs, history['val_accuracy'], 'b', label='Validation accuracy')\n",
    "\n",
    "  ax2 = ax.twinx()\n",
    "  ax2.plot(epochs, history[\"lr\"],\"orange\",label='Learning rate')\n",
    "  ax2.set_yscale(\"log\")\n",
    "\n",
    "\n",
    "  plt.title(\"Courbe d'entrainement\")\n",
    "  plt.legend(loc=0)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "# plot_history(history, classes = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lBjpRv8Vt-s"
   },
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "a_CbNhn5ete5"
   },
   "outputs": [],
   "source": [
    "def predict(model, test_generator, nom, classes=4):\n",
    "  \n",
    "  predict = model.predict_generator(test_generator)  \n",
    "\n",
    "  if classes == \"regression\":\n",
    "    y_true = test_generator.labels\n",
    "    y_pred = np.maximum(np.minimum(np.round(predict,0).reshape(-1).astype('int'),3),0)\n",
    "  else:\n",
    "    y_true = test_generator.classes\n",
    "    y_pred = np.argmax(predict, axis = 1)\n",
    "\n",
    "  pd.DataFrame({\"y_true\" : y_true,  \"y_pred\" : y_pred}).to_csv(join(FOLDER_MODELS, f\"{nom}/{nom}-predictions.csv\"))\n",
    "\n",
    "  return y_true, y_pred\n",
    "\n",
    "def evaluate_model(model, test_generator, nom, classes=4):\n",
    "\n",
    "  y_true, y_pred = predict(model, test_generator, nom, classes=classes)\n",
    "\n",
    "  # Calculate and print the metrics results\n",
    "  from sklearn.metrics import confusion_matrix, cohen_kappa_score, classification_report, accuracy_score, f1_score\n",
    "\n",
    "  acc = accuracy_score( y_true, y_pred)\n",
    "  print(f\"Accuracy : {acc:.4f}\")\n",
    "\n",
    "  f1 = f1_score(y_true, y_pred, average = \"weighted\")\n",
    "  print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "  k = cohen_kappa_score(y_true, y_pred, weights = 'quadratic')\n",
    "  print(f\"Quadratic weighted Cohen's kappa = {k:.4f}\")\n",
    "  print(\"\")\n",
    "\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "  print('Confusion matrix:')\n",
    "  print(cm)\n",
    "  print('')\n",
    "\n",
    "  cr = classification_report(y_true, y_pred)\n",
    "  print('Classification report:')\n",
    "  print(cr)\n",
    "  print('')\n",
    "\n",
    "\n",
    "  y_true_binary = np.array(y_true) >= 1\n",
    "  y_pred_binary = np.array(y_pred) >= 1\n",
    "\n",
    "  acc_binary = accuracy_score( y_true_binary, y_pred_binary)\n",
    "\n",
    "  print(f\"Accuracy (binary) : {acc_binary:.4f}\")\n",
    "\n",
    "  f1_binary = f1_score(y_true_binary, y_pred_binary, average = \"weighted\")\n",
    "  print(f\"F1 Score (binary) : {f1_binary:.4f}\")\n",
    "\n",
    "  k_binary = cohen_kappa_score(y_true_binary, y_pred_binary, weights = 'quadratic')\n",
    "  print(f\"Quadratic weighted Cohen's kappa (binary) : {k_binary:.4f}\")\n",
    "  print(\"\")\n",
    "\n",
    "  cm_binary = confusion_matrix(y_true_binary, y_pred_binary)\n",
    "  print('Confusion matrix (binary) :')\n",
    "  print(cm_binary)\n",
    "  print('')\n",
    "\n",
    "  cr_binary = classification_report(y_true_binary, y_pred_binary)\n",
    "  print('Classification report (binary) :')\n",
    "  print(cr_binary)\n",
    "  print('')\n",
    "\n",
    "  import json\n",
    "\n",
    "  metrics = {\"acc\" : acc, \"f1\": f1, \"kappa\" : k, \n",
    "          \"acc_binary\" : acc_binary, \"f1_binary\" : f1_binary, \"k_binary\" : k_binary }\n",
    "\n",
    "  with open( join(FOLDER_MODELS, f\"{nom}/{nom}-metrics.json\"), 'w') as f:\n",
    "    json.dump( metrics, f )\n",
    "\n",
    "  return metrics\n",
    "\n",
    "# metrics = eval_model(model, test_generator, nom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1o2JWaEGoe-t"
   },
   "source": [
    "# Classe d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OWoLdqnjJX3R"
   },
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "\n",
    "  def __init__(self,model, nom_modele, preprocess_input=None, image_small=True, classes=4, augmentation = 2, retrain = False, rescale = 1):\n",
    "    self.model = model\n",
    "    self.nom_modele = nom_modele\n",
    "    self.preprocess_input = preprocess_input\n",
    "    self.retrain = retrain\n",
    "    self.classes = classes\n",
    "\n",
    "    self.nom = f\"{nom_modele}-{'retrain' if retrain else 'transfert'}-{'small' if image_small else 'full'}-{classes}-A{augmentation}\"\n",
    "    print(f\"Entrainement et évaluation #{self.nom}\\n\")\n",
    "\n",
    "    augmentation_input = globals()[f\"augmentation_{augmentation}\"]\n",
    "\n",
    "    print(\"-- Creation des générateurs\")\n",
    "\n",
    "    self.train_generator, self.validation_generator, self.test_generator = get_generators( images_small = image_small, \n",
    "                                                                       classes = classes, \n",
    "                                                                       preprocess_input = self.preprocess_input, \n",
    "                                                                       augmentation_input = augmentation_input, \n",
    "                                                                       rescale = rescale\n",
    "                                                                      )\n",
    "  def fit(self, epochs=(50,50), lr = (5e-3, 5e-4)):\n",
    "    \n",
    "    print(\"\\n-- Début de l'entrainement\")\n",
    "    self.history = train_model(self.model, self.nom, self.train_generator, self.validation_generator, self.classes, epochs=epochs, retrain = self.retrain, lr=lr)\n",
    "\n",
    "    print(\"\\n-- Courbe d'entrainement\")\n",
    "    plot_history(self.history, self.classes)\n",
    "\n",
    "  def score(self):\n",
    "    print(\"\\n-- Métriques\")\n",
    "    metrics = evaluate_model(self.model, self.test_generator, self.nom, self.classes)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-m4juF8VgO3"
   },
   "source": [
    "# Création des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NZEliOdcYUoB"
   },
   "outputs": [],
   "source": [
    "def get_EffNet(classes = 4):\n",
    "  \n",
    "  from tensorflow.keras.applications.efficientnet import EfficientNetB7, preprocess_input\n",
    "\n",
    "  model_effnet = EfficientNetB7(include_top=False, \n",
    "                              input_shape=(256,256,3)\n",
    "                            )\n",
    "\n",
    "  sub_model = Model(model_effnet.input, model_effnet.output)\n",
    "  sub_model.trainable = False\n",
    "\n",
    "  globavpool = GlobalAveragePooling2D()(sub_model.output)\n",
    "  middle_layer = Dense(512, activation=\"relu\")(globavpool)\n",
    "\n",
    "  if classes == \"regression\":\n",
    "    last_layer = Dense(1)(middle_layer)\n",
    "  else:\n",
    "    last_layer = Dense(classes, activation=\"softmax\")(middle_layer)\n",
    "\n",
    "  model = Model(inputs=sub_model.input, outputs=last_layer)\n",
    "\n",
    "  nom_modele = \"EfficientNetB7v1\"\n",
    "  \n",
    "  return model, nom_modele, preprocess_input\n",
    "\n",
    "def get_EffNetv2(classes = 4):\n",
    "  \n",
    "  from tensorflow.keras.applications.efficientnet import EfficientNetB7, preprocess_input\n",
    "\n",
    "  model_effnet = EfficientNetB7(include_top=False, \n",
    "                              input_shape=(256,256,3)\n",
    "                            )\n",
    "\n",
    "  sub_model = Model(model_effnet.input, model_effnet.output)\n",
    "  sub_model.trainable = False\n",
    "\n",
    "  globavpool = GlobalAveragePooling2D()(sub_model.output)\n",
    "  middle_layer = Dense(512, activation=\"relu\")(globavpool)\n",
    "  dropout = Dropout(0.3)(middle_layer)\n",
    "\n",
    "  if classes == \"regression\":\n",
    "    last_layer = Dense(1)(dropout)\n",
    "  else:\n",
    "    last_layer = Dense(classes, activation=\"softmax\")(dropout)\n",
    "\n",
    "  model = Model(inputs=sub_model.input, outputs=last_layer)\n",
    "\n",
    "  nom_modele = \"EfficientNetB7v2\"\n",
    "  \n",
    "  return model, nom_modele, preprocess_input\n",
    "\n",
    "# tensorflow.keras.utils.plot_model(get_EffNet()[0])\n",
    "def get_ResNet(classes = 4):\n",
    "\n",
    "  from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "\n",
    "  model_resnet_transfert = ResNet50V2(include_top=False, \n",
    "                            input_shape=(224,224,3)\n",
    "                            )\n",
    "\n",
    "  sub_model_resnet = Model(model_resnet_transfert.input, model_resnet_transfert.output)\n",
    "  sub_model_resnet.trainable = False  \n",
    "\n",
    "  globavpool = GlobalAveragePooling2D()(sub_model_resnet.output)\n",
    "  middle_layer = Dense(512, activation=\"relu\")(globavpool)\n",
    "  dropout = Dropout(0.3)(middle_layer)\n",
    "  \n",
    "  if classes == \"regression\":\n",
    "    last_layer = Dense(1)(dropout)\n",
    "  else:\n",
    "    last_layer = Dense(classes, activation=\"softmax\")(dropout)\n",
    "\n",
    "  model_resnet = Model(inputs=sub_model_resnet.input, outputs=last_layer)\n",
    "\n",
    "  nom_modele = \"ResNet50V2\"\n",
    "\n",
    "  return model_resnet, nom_modele, preprocess_input\n",
    "\n",
    "\n",
    "def getVGG16(weights='imagenet'):\n",
    "\n",
    "  from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "  model_transfert = VGG16(include_top=False, \n",
    "                              weights='imagenet',\n",
    "                            input_shape=(256,256,3)\n",
    "                            )\n",
    "\n",
    "  sub_model = Model(model_transfert.input, model_transfert.output)\n",
    "  sub_model.trainable = False  \n",
    "\n",
    "  flatten = Flatten()(sub_model.output)\n",
    "  layer1 = Dense(4096, activation=\"relu\")(flatten)\n",
    "  layer2 = Dense(4096, activation=\"relu\")(layer1)\n",
    "  last_layer = Dense(4, activation=\"softmax\")(layer2)\n",
    "  model_resnet = Model(inputs=sub_model.input, outputs=last_layer)\n",
    "\n",
    "  nom_modele = \"VGG16\"+(weights if weights else \"FromScratch\")\n",
    "\n",
    "  return model_resnet, nom_modele, preprocess_input\n",
    "\n",
    "# getVGG16()[0].summary()\n",
    "\n",
    "\n",
    "def getVGG19(weights='imagenet'):\n",
    "\n",
    "  from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "\n",
    "  model_transfert = VGG19(include_top=False, \n",
    "                              weights='imagenet',\n",
    "                            input_shape=(256,256,3)\n",
    "                            )\n",
    "\n",
    "  sub_model = Model(model_transfert.input, model_transfert.output)\n",
    "  sub_model.trainable = False  \n",
    "\n",
    "  flatten = Flatten()(sub_model.output)\n",
    "  layer1 = Dense(4096, activation=\"relu\")(flatten)\n",
    "  layer2 = Dense(4096, activation=\"relu\")(layer1)\n",
    "  last_layer = Dense(4, activation=\"softmax\")(layer2)\n",
    "  model_resnet = Model(inputs=sub_model.input, outputs=last_layer)\n",
    "\n",
    "  nom_modele = \"VGG19\"+(weights if weights else \"FromScratch\")\n",
    "\n",
    "  return model_resnet, nom_modele, preprocess_input\n",
    "\n",
    "# getVGG19()[0].summary()\n",
    "\n",
    "\n",
    "def get_CustomCNNv1():\n",
    "  from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "  model_CustomCNNv1 = Sequential([\n",
    "                              Input(shape=(256,256,3)),\n",
    "                              Conv2D(32, (9, 9),strides = 3, activation=\"relu\", padding=\"same\"),\n",
    "                              Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "                              MaxPooling2D((2, 2), padding=\"same\"),\n",
    "                              Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "                              Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "                              MaxPooling2D((2, 2), padding=\"same\"),\n",
    "                              Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "                              Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "                              MaxPooling2D((2, 2), padding=\"same\"),\n",
    "                              Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "                              Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "                              MaxPooling2D((2, 2), padding=\"same\"),\n",
    "                              Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "                              Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "                              MaxPooling2D((2, 2), padding=\"same\"),\n",
    "                              Flatten(),\n",
    "                              Dropout(0.3),\n",
    "                              Dense(4, activation=\"softmax\"),                            \n",
    "                              ])\n",
    "\n",
    "\n",
    "  # model_custom1.summary()  \n",
    "\n",
    "  nom_modele = \"CustomCNNv1\"\n",
    "\n",
    "  return model_CustomCNNv1, nom_modele, None\n",
    "\n",
    "# get_CustomCNNv1()[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rDBA1O96kimx",
    "outputId": "f890cd62-319e-45c3-d7f4-64a9d1f4a8f3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 2s 0us/step\n",
      "58900480/58889256 [==============================] - 2s 0us/step\n",
      "Entrainement et évaluation #VGG16imagenet-retrain-small-4-A2\n",
      "\n",
      "-- Creation des générateurs\n",
      "Found 4156 validated image filenames belonging to 4 classes.\n",
      "Found 881 validated image filenames belonging to 4 classes.\n",
      "Found 889 validated image filenames belonging to 4 classes.\n",
      "\n",
      "-- Début de l'entrainement\n",
      "Epoch 1/50\n",
      "130/130 [==============================] - 123s 914ms/step - loss: 11.6124 - accuracy: 0.4846 - val_loss: 0.9363 - val_accuracy: 0.5902 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 102s 783ms/step - loss: 0.9744 - accuracy: 0.5895 - val_loss: 0.9234 - val_accuracy: 0.6277 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 101s 779ms/step - loss: 0.9610 - accuracy: 0.5922 - val_loss: 0.8825 - val_accuracy: 0.6300 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 90s 694ms/step - loss: 0.9646 - accuracy: 0.6095 - val_loss: 1.0829 - val_accuracy: 0.5846 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 88s 677ms/step - loss: 0.8963 - accuracy: 0.6249 - val_loss: 0.8846 - val_accuracy: 0.6493 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 100s 770ms/step - loss: 0.8930 - accuracy: 0.6393 - val_loss: 0.8619 - val_accuracy: 0.6447 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 90s 691ms/step - loss: 0.8646 - accuracy: 0.6506 - val_loss: 0.9507 - val_accuracy: 0.6084 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 88s 678ms/step - loss: 0.8569 - accuracy: 0.6598 - val_loss: 0.9337 - val_accuracy: 0.6583 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 100s 771ms/step - loss: 0.8308 - accuracy: 0.6682 - val_loss: 0.8536 - val_accuracy: 0.6674 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 89s 689ms/step - loss: 0.8307 - accuracy: 0.6523 - val_loss: 0.8588 - val_accuracy: 0.6708 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 99s 760ms/step - loss: 0.8168 - accuracy: 0.6658 - val_loss: 0.8175 - val_accuracy: 0.6833 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 89s 686ms/step - loss: 0.8182 - accuracy: 0.6588 - val_loss: 0.8278 - val_accuracy: 0.6799 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 87s 671ms/step - loss: 0.8217 - accuracy: 0.6670 - val_loss: 0.8989 - val_accuracy: 0.6720 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 88s 675ms/step - loss: 0.7874 - accuracy: 0.6759 - val_loss: 0.8531 - val_accuracy: 0.6572 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 87s 672ms/step - loss: 0.7461 - accuracy: 0.6935 - val_loss: 0.8418 - val_accuracy: 0.6652 - lr: 1.5000e-04\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 99s 759ms/step - loss: 0.7374 - accuracy: 0.6906 - val_loss: 0.7851 - val_accuracy: 0.6754 - lr: 1.5000e-04\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 90s 689ms/step - loss: 0.7264 - accuracy: 0.7028 - val_loss: 0.8018 - val_accuracy: 0.6799 - lr: 1.5000e-04\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 99s 762ms/step - loss: 0.7372 - accuracy: 0.7002 - val_loss: 0.7804 - val_accuracy: 0.6913 - lr: 1.5000e-04\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 90s 691ms/step - loss: 0.7127 - accuracy: 0.7031 - val_loss: 0.7804 - val_accuracy: 0.6890 - lr: 1.5000e-04\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 88s 680ms/step - loss: 0.7159 - accuracy: 0.6997 - val_loss: 0.7984 - val_accuracy: 0.6947 - lr: 1.5000e-04\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 88s 680ms/step - loss: 0.7150 - accuracy: 0.6956 - val_loss: 0.8062 - val_accuracy: 0.6879 - lr: 1.5000e-04\n",
      "Epoch 22/50\n",
      "130/130 [==============================] - 88s 679ms/step - loss: 0.6922 - accuracy: 0.7168 - val_loss: 0.8064 - val_accuracy: 0.6913 - lr: 4.5000e-05\n",
      "Epoch 23/50\n",
      "130/130 [==============================] - 88s 679ms/step - loss: 0.6962 - accuracy: 0.7093 - val_loss: 0.7984 - val_accuracy: 0.6867 - lr: 4.5000e-05\n",
      "Epoch 24/50\n",
      "130/130 [==============================] - 88s 678ms/step - loss: 0.6767 - accuracy: 0.7170 - val_loss: 0.7825 - val_accuracy: 0.6958 - lr: 4.5000e-05\n",
      "Epoch 25/50\n",
      "130/130 [==============================] - 88s 677ms/step - loss: 0.6938 - accuracy: 0.7120 - val_loss: 0.7880 - val_accuracy: 0.6947 - lr: 1.3500e-05\n",
      "Epoch 1/50\n",
      "130/130 [==============================] - 145s 1s/step - loss: 1.1035 - accuracy: 0.5108 - val_loss: 0.9661 - val_accuracy: 0.6084 - lr: 5.0000e-05\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 136s 1s/step - loss: 0.9038 - accuracy: 0.6203 - val_loss: 0.8753 - val_accuracy: 0.6765 - lr: 5.0000e-05\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 148s 1s/step - loss: 0.8109 - accuracy: 0.6574 - val_loss: 0.7791 - val_accuracy: 0.6527 - lr: 5.0000e-05\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 137s 1s/step - loss: 0.7560 - accuracy: 0.6800 - val_loss: 0.8833 - val_accuracy: 0.6288 - lr: 5.0000e-05\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 147s 1s/step - loss: 0.7287 - accuracy: 0.6971 - val_loss: 0.7133 - val_accuracy: 0.7162 - lr: 5.0000e-05\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 148s 1s/step - loss: 0.6700 - accuracy: 0.7226 - val_loss: 0.6719 - val_accuracy: 0.7333 - lr: 5.0000e-05\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 137s 1s/step - loss: 0.6654 - accuracy: 0.7211 - val_loss: 0.6750 - val_accuracy: 0.7480 - lr: 5.0000e-05\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 147s 1s/step - loss: 0.6281 - accuracy: 0.7324 - val_loss: 0.5991 - val_accuracy: 0.7730 - lr: 5.0000e-05\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 137s 1s/step - loss: 0.5938 - accuracy: 0.7570 - val_loss: 0.7607 - val_accuracy: 0.7094 - lr: 5.0000e-05\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 135s 1s/step - loss: 0.5538 - accuracy: 0.7707 - val_loss: 0.6319 - val_accuracy: 0.7571 - lr: 5.0000e-05\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 135s 1s/step - loss: 0.5302 - accuracy: 0.7813 - val_loss: 0.8663 - val_accuracy: 0.7287 - lr: 5.0000e-05\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 149s 1s/step - loss: 0.4633 - accuracy: 0.8087 - val_loss: 0.5169 - val_accuracy: 0.8059 - lr: 1.5000e-05\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 137s 1s/step - loss: 0.4280 - accuracy: 0.8239 - val_loss: 0.6521 - val_accuracy: 0.7514 - lr: 1.5000e-05\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 147s 1s/step - loss: 0.4003 - accuracy: 0.8316 - val_loss: 0.5064 - val_accuracy: 0.8002 - lr: 1.5000e-05\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 137s 1s/step - loss: 0.3809 - accuracy: 0.8410 - val_loss: 0.5643 - val_accuracy: 0.8014 - lr: 1.5000e-05\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 135s 1s/step - loss: 0.3636 - accuracy: 0.8508 - val_loss: 0.5315 - val_accuracy: 0.8036 - lr: 1.5000e-05\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 135s 1s/step - loss: 0.3656 - accuracy: 0.8448 - val_loss: 0.5308 - val_accuracy: 0.7934 - lr: 1.5000e-05\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 135s 1s/step - loss: 0.3141 - accuracy: 0.8722 - val_loss: 0.5616 - val_accuracy: 0.8036 - lr: 4.5000e-06\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 135s 1s/step - loss: 0.3026 - accuracy: 0.8718 - val_loss: 0.5374 - val_accuracy: 0.8025 - lr: 4.5000e-06\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 136s 1s/step - loss: 0.3003 - accuracy: 0.8785 - val_loss: 0.5583 - val_accuracy: 0.7968 - lr: 4.5000e-06\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 137s 1s/step - loss: 0.2779 - accuracy: 0.8864 - val_loss: 0.5622 - val_accuracy: 0.7980 - lr: 1.3500e-06\n",
      "\n",
      "-- Courbe d'entrainement\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3wV1fLAv0PoRboiRYp0RFoExaeAiqIoKjwVsIBYn2Jv2BV7eU/0Z3kPKyKKHVERBAWxAkGK0iFECSrSewuZ3x+zN9wkN8kNpN7M9/PZz7179pyzZzc3s7Nz5syIquI4juPELqUKewCO4zhO/uKC3nEcJ8ZxQe84jhPjuKB3HMeJcVzQO47jxDgu6B3HcWIcF/ROkUFE3hCRh/Op7wdE5K386PtgEZH/isi9hT0OJ3ZxQe9ki4gMFJEEEdkmIn+KyBci8o/CHtfBICKNRCQpj/pKEpFTDqYPVb1aVR/Ki/EUFEX5welkxgW9kyUicjMwAngUOAw4AngRODsfzhWX130WBUSkdGGPwXFc0DsREZGqwHDgWlX9SFW3q+peVf1UVW8L6pQTkREi8kewjRCRcsGxwSLyXYY+VUSaBt/fEJGXRGSCiGwHegTVaonIZBHZKiLfiEjDsPYtg2MbRGSJiJyfzfgbB+23ishkoFY2deuKyIcislZEVorI9WHHHhCR90TkzaCvBSISHxwbjT38Pg3eeG4P3hZURC4Tkd+Br4O674vIXyKyWUSmi0ibsHOkmaxEpLuIJIvILSLyd/AWdWlY3XIi8rSI/C4iawKzT4UMbW8Pa3uOiJwhIkuD+3ZXWF+lRGSYiKwQkfXBddYIjoWuY1BwrnUicndwrBdwF3BBcN3zsrq3TtHABb2TFccB5YGPs6lzN3As0B5oB3QG7snFOQYCjwBVgNBD4ULgIUwwzwXGAIhIJWAy8DZwKNAfeFFEWmfR99vA7KCfh4BBoQOqmqSqjYJ+SwGfAvOAesDJwI0iclpYX32AsUA1YDzwfNDPxcDvwFmqWllVnwxr0w1oBYT6+QJoFoz959B1ZUEdoGownsuAF0SkenDscaA5ds+bBnXuy9C2fFj5y8BFQCfgBOBeEWkc1L0OOCcYa11gI/BChrH8A2gR3Jf7RKSVqk7E3vLeDa67XTbX4hQFVNU33zJtmMD9K4c6K4AzwvZPA5KC74OB7zLUV6Bp8P0N4M0Mx98AxobtVwb2AQ2AC4BvM9T/H3B/hHEdAaQAlcLK3gbeilC3C/B7hrI7gdeD7w8AU8KOtQZ2hu0nAaeE7TcKrrNJNvetWlCnath1Pxx87w7sBEqH1f8be6AKsB04MuzYccDKDG3jgv0qwXm6hNWfDZwTfF8EnBx27HBgL1A67Drqhx2fCfQPuy+Z7qdvRXNz+6GTFesxM0ppVU3Jok5d4Lew/d+CsmhZlV2Zqm4TkQ1Bnw2BLiKyKaxuaWB0FuPaqKrbM4ytQYS6DYG6GfqNA74N2/8r7PsOoHwO9yXddQTzD48A5wG1gdTgUC1gc4S26zP0vQN76NUGKgKzRSSt+2C84W33Bd93Bp9rwo7vDPoCu/aPRSQ17Pg+bD4mRMZrr4xT7HBB72TFj8Bu7NX+gyzq/IEJiwXB/hFBGZjmWTFUUUTqRGgfKXRqmjAWkcpAjaDPVcA3qtozirH/CVQXkUphwv6ILM63CtOIm0XRbySyCv8aXj4Qm8A+BXsDqIqZSSRzs2xZhwnqNqq6OpdtI7EKGKKq32c8ICKNcmjrYW+LEW6jdyKiqpsxG+8LwYReRREpIyKni0jIFv0OcI+I1BaRWkH9kMvdPKCNiLQXkfLYq340nCEi/xCRspht/SdVXQV8BjQXkYuDcZQRkWNEpFWEsf8GJAAPikhZMXfQs7I430xgq4jcISIVRCRORI4SkWOiHO8aoEkOdapgD8312MPv0Sj7ToeqpmI292dE5FAAEamXYT4hN/wXeCQ04R38HaP1qFoDNArmOJwijv+RnCxR1X8DN2MTrGsxDXAoMC6o8jAmUOcDv2CTjA8HbZdiXjtTgGXsn2zNibeB+4EN2ATiRUF/W4FTsUnYPzCTwhNAuSz6GYjZ3zcE/b2ZxTXuA87EJjdXYlrzK5jWHQ2PYQ+7TSJyaxZ13sRMR6uBhcBPUfYdiTuA5cBPIrIFu78tDrCvZ7HJ5S9FZGswri5Rtn0/+FwvIj8f4PmdAkKCiRXHcRwnRnGN3nEcJ8ZxQe84jhPjuKB3HMeJcVzQO47jxDhR+dEHsS2exRZmvKKqj2c43hB4DVvQsQG4SFWTg2OD2L8s/mFVHZXduWrVqqWNGjXKzTU4juOUeGbPnr1OVWtHOpaj102wqm8p0BNIBmYBA1R1YVid94HPVHWUiJwEXKqqFwcBkhKAeGyBxWygk6puzOp88fHxmpCQkKsLdBzHKemIyGxVjY90LBrTTWdguaomquoeLLhTxkUVrQmi9AFTw46fBkxW1Q2BcJ8M9MrtBTiO4zgHTjSCvh7pY5IkB2XhzAP6Bt/PBaqISM0o2zqO4zj5SF5Nxt4KdBOROVjI09VYcKSoEJErxbIYJaxduzaPhuQ4juNAdJOxq0kf9a9+UJaGqv5BoNEHgaj6qeomEVmNhU4Nbzst4wlUdSQwEsxGn/H43r17SU5OZteuXVEM1ykJlC9fnvr161OmTJnCHorjFHmiEfSzgGZBsoLVWKyRgeEVgoBWG4KgS3diHjgAk4BHw5ImnBoczxXJyclUqVKFRo0aERae1SmhqCrr168nOTmZxo0b59zAcUo4OZpugrjYQzGhvQh4T1UXiMhwEekTVOsOLBGRpVgs60eCthuwCISzgm14UJYrdu3aRc2aNV3IOwCICDVr1vQ3PMeJkqj86FV1AjAhQ9l9Yd8/IIuY5ar6Gvs1/APGhbwTjv8eHCd6fGWs4zhOYaMKH30Er7ySL927oI+C9evX0759e9q3b0+dOnWoV69e2v6ePXuybZuQkMD111+f4zm6du2aV8N1HKc4MX8+nHwy9OsHr75qQj+P8VSCUVCzZk3mzp0LwAMPPEDlypW59db9OSZSUlIoXTryrYyPjyc+PuJitXT88MMPeTPYAmTfvn3ExcXlXNFxnMysWwf33Qf/+x9UqwYvvABXXgn5YJZ0jf4AGTx4MFdffTVdunTh9ttvZ+bMmRx33HF06NCBrl27smTJEgCmTZvGmWeeCdhDYsiQIXTv3p0mTZrw3HPPpfVXuXLltPrdu3fnn//8Jy1btuTCCy8kFKZiwoQJtGzZkk6dOnH99den9RtOUlISJ5xwAh07dqRjx47pHiBPPPEEbdu2pV27dgwbNgyA5cuXc8opp9CuXTs6duzIihUr0o0ZYOjQobzxxhsANGrUiDvuuIOOHTvy/vvv8/LLL3PMMcfQrl07+vXrx44dOwBYs2YN5557Lu3ataNdu3b88MMP3HfffYwYMSKt37vvvptnn332oP8WjlOs2LsXnnsOmjWDkSPh2mth2TK45hrIQmE8WIqfRn/jjRBo13lG+/YQJoCiJTk5mR9++IG4uDi2bNnCt99+S+nSpZkyZQp33XUXH374YaY2ixcvZurUqWzdupUWLVrwr3/9K5Mv+Jw5c1iwYAF169bl+OOP5/vvvyc+Pp6rrrqK6dOn07hxYwYMGBBxTIceeiiTJ0+mfPnyLFu2jAEDBpCQkMAXX3zBJ598wowZM6hYsSIbNpjz04UXXsiwYcM499xz2bVrF6mpqaxatSpi3yFq1qzJzz9b9rj169dzxRVXAHDPPffw6quvct1113H99dfTrVs3Pv74Y/bt28e2bduoW7cuffv25cYbbyQ1NZWxY8cyc+bMXN93xymWpKbC+PFw112waBH07AnPPANt2uT7qYufoC9CnHfeeWmmi82bNzNo0CCWLVuGiLB3796IbXr37k25cuUoV64chx56KGvWrKF+/frp6nTu3DmtrH379iQlJVG5cmWaNGmS5jc+YMAARo4cman/vXv3MnToUObOnUtcXBxLly4FYMqUKVx66aVUrFgRgBo1arB161ZWr17NueeeC9gipGi44IIL0r7/+uuv3HPPPWzatIlt27Zx2mmWp/rrr7/mzTctTWtcXBxVq1alatWq1KxZkzlz5rBmzRo6dOhAzZo1ozqn4xRbUlPhww/hoYfgl19Mk//kEzjrrHwx00Si+An6A9C884tKlSqlfb/33nvp0aMHH3/8MUlJSXTv3j1im3Ll9ueyjouLIyUl5YDqZMUzzzzDYYcdxrx580hNTY1aeIdTunRpUlNT0/Yz+quHX/fgwYMZN24c7dq144033mDatGnZ9n355Zfzxhtv8NdffzFkyJBcj81xig379sG778LDD5sG36IFjB4N/fvnm4kmK9xGn0ds3ryZevUsXlvInp2XtGjRgsTERJKSkgB49913sxzH4YcfTqlSpRg9ejT79lnIoZ49e/L666+n2dA3bNhAlSpVqF+/PuPGjQNg9+7d7Nixg4YNG7Jw4UJ2797Npk2b+Oqrr7Ic19atWzn88MPZu3cvY8aMSSs/+eSTeemllwCbtN28eTMA5557LhMnTmTWrFlp2r/jFEtefhkeeACeeMJs7i+/bIL8gw9sgrVVK7jwQoiLg7FjYcECuOiiAhfyUBw1+iLK7bffzqBBg3j44Yfp3bt3nvdfoUIFXnzxRXr16kWlSpU45phjIta75ppr6NevH2+++WZaXYBevXoxd+5c4uPjKVu2LGeccQaPPvooo0eP5qqrruK+++6jTJkyvP/++zRp0oTzzz+fo446isaNG9OhQ4csx/XQQw/RpUsXateuTZcuXdi6dSsAzz77LFdeeSWvvvoqcXFxvPTSSxx33HGULVuWHj16UK1aNffYcYov06ebh0x2tG9vJptzzoFShatT55h4pKCJlHhk0aJFtGrVqpBGVHTYtm0blStXRlW59tpradasGTfddFNhDytXpKampnnsNGvW7KD68t+FU2icfDIsXAjLl5udfefO9BtA27YFZoOH7BOPuEZfjHj55ZcZNWoUe/bsoUOHDlx11VWFPaRcsXDhQs4880zOPffcgxbyjlNoTJ8OX39tHjOh+arAyaGo4hq9U2zx34VTKJx0kk2uJiZChQqFPZo0XKN3HMfJC775BqZONW2+CAn5nHCvG8dxnGh58EGoUweKmdnUNXrHcZxoCGnzI0YUK20eXKN3HMeJjgceMG0+J7fKIkhUgl5EeonIEhFZLiLDIhw/QkSmisgcEZkvImcE5Y1EZKeIzA22/+b1BRQEPXr0YNKkSenKRowYwb/+9a8s23Tv3p3QpPIZZ5zBpk2bMtV54IEHePrpp7M997hx41i4cGHa/n333ceUKVNyM3zHcQ6WadNsGzas2GnzEIWgF5E44AXgdKA1MEBEWmeodg+WYrADllP2xbBjK1S1fbBdnUfjLlAGDBjA2LFj05WNHTs2y8BiGZkwYQLVqlU7oHNnFPTDhw/nlFNOOaC+CovQ6lzHKbY88AAcfnix1OYhOo2+M7BcVRNVdQ8wFjg7Qx0FDgm+VwX+yLshFj7//Oc/+fzzz9OSjCQlJfHHH39wwgkn8K9//Yv4+HjatGnD/fffH7F9o0aNWLduHQCPPPIIzZs35x//+EdaKGMgYrjfH374gfHjx3PbbbfRvn17VqxYweDBg/ngA8va+NVXX9GhQwfatm3LkCFD2L17d9r57r//fjp27Ejbtm1ZvHhxpjF5OGPHATZtgosvhiOPtInWNWsy15k2zezzxVSbB0BVs92AfwKvhO1fDDyfoc7hwC9AMrAR6BSUNwK2A3OAb4ATsjjHlUACkHDEEUdoRhYuXJj2/YYbVLt1y9vthhsynTITvXv31nHjxqmq6mOPPaa33HKLqqquX79eVVVTUlK0W7duOm/ePFVV7datm86aNUtVVRs2bKhr167VhIQEPeqoo3T79u26efNmPfLII/Wpp55SVdV169alnevuu+/W5557TlVVBw0apO+//37asdD+zp07tX79+rpkyRJVVb344ov1mWeeSTtfqP0LL7ygl112Wabr2b59u+7cuVNVVZcuXaqdOnVSVdUJEybocccdp9u3b093fZ07d9aPPvpIVVV37typ27dv16lTp2rv3r3T+rz22mv19ddfTxvDE088kXYsq+s7//zz08adkpKimzZt0pUrV2qHDh1UVXXfvn3apEmTdO1DhP8uHCfXfPutasOGqnFxqv/4hyqoli2rOniw6ty5++t166Z6+OGqO3YU1kijAkjQLOR4Xk3GDgDeUNX6wBnAaBEpBfwJHKFm0rkZeFtEDsnYWFVHqmq8qsbXrl07j4aUt4Sbb8LNNu+99x4dO3akQ4cOLFiwIJ2ZJSPffvst5557LhUrVuSQQw6hT58+acd+/fVXTjjhBNq2bcuYMWNYsGBBtuNZsmQJjRs3pnnz5gAMGjSI6dOnpx3v27cvAJ06dUoLhBbO3r17ueKKK2jbti3nnXde2rijDWdcMYqVgBnDGUe6vq+//jptriMUzrhRo0Zp4Yy//PJLD2fs5C0pKWaK6dbNAo59/z18+y0sXgyXXw7vvWdxak46CR59tPhr80TnXrkaaBC2Xz8oC+cyoBeAqv4oIuWBWqr6N7A7KJ8tIiuA5pj2fkAUVpTis88+m5tuuomff/6ZHTt20KlTJ1auXMnTTz/NrFmzqF69OoMHD84U0jdachvuNydCoY6zCnPs4YydEsnKlRZB8ocf4JJL4P/+Dw4JdM8WLSyd38MPW5Lu//s/c6csxrb5ENFo9LOAZiLSWETKYpOt4zPU+R04GUBEWgHlgbUiUjuYzEVEmgDNgMS8GnxBUrlyZXr06MGQIUPStPktW7ZQqVIlqlatypo1a/jiiy+y7ePEE09k3Lhx7Ny5k61bt/Lpp5+mHcsq3G+VKlXSIkKG06JFC5KSkli+fDkAo0ePplu3blFfj4czdkoc77xjmvqvv8KYMTBq1H4hH0716nDbbRbi4OOPLSvUAShCRYkcBb2qpgBDgUnAIsy7ZoGIDBeRkO3hFuAKEZkHvAMMDmxGJwLzRWQu8AFwtapuyI8LKQgGDBjAvHnz0gR9u3bt6NChAy1btmTgwIEcf/zx2bbv2LEjF1xwAe3ateP0009PF2o4FO73+OOPp2XLlmnl/fv356mnnqJDhw6sWLEirbx8+fK8/vrrnHfeebRt25ZSpUpx9dXROzVdc801jBo1inbt2rF48eJ04Yz79OlDfHw87du3T3P/HD16NM899xxHH300Xbt25a+//qJBgwZp4YzPP//8qMIZZ7y+Z599lqlTp9K2bVs6deqUZkIKhTM+//zzPZyxc3Bs2AADB9p21FGWinTgwJzblS5tIYbjI4aPKVZ4UDOnSBJNOGP/XTg5MmGC2d3XroX77oM77yyUxB8FQXZBzXxlrFPkWLhwIU2bNuXkk0/2cMbOgbF1q9nVe/eGGjVgxgy4996YFfI5UTKv2inStG7dmsTEYjmV4xQFvvkGBg+G336D22+H4cMhLA9zSaTYaPRFzcTkFC7+e3AysWUL3HQT9OhhbpPffmv5XEu4kIdiIujLly/P+vXr/Z/bAUzIr1+//oBcQp0YJCUFXnoJmjY1/+urr7YJ1xycI0oSxcJ0U79+fZKTk1m7dm1hD8UpIpQvX5769esX9jCcwkQVvvgCbr3VMj6deKJNvsaAl0xeUywEfZkyZWjcuHFhD8NxnKLC/Plwyy0wZYpp8h9/DGefXaDJuIsTxcJ04ziOA5gWf8sttvBp9mwz1SxYYP7uLuSzpFho9I7jOADcdRf85z/mOvnYY+Y66eSIC3rHcYoHI0bA44/bZOuLL7oGnwvcdOM4TtHnnXfMdbJfP3j+eRfyucQFveM4RZsvv4RBg6B7d3jrLfORd3KFC3rHcYous2ZB377QujWMG1fso0gWFi7oHccpmixdCmecAYceav7yVasW9oiKLS7oHccpevz5J5x2mtniJ02y5B/OAeNeN47jFD2uvtpCC0+bBh7B9KBxjd5xnKLF7NmMGl+Ni4780cMZ5BFRafQi0gt4FogDXlHVxzMcPwIYBVQL6gxT1QnBsTuxnLL7gOtVdVLeDd9xnJjjwQd5p/QNTJrflqf+zHurze7dZv5fuNC2BQtsjvepp6I/1++/W4idLVugdu3026GHQt260LEjlCoiqnSOgj7I+foC0BNIBmaJyHhVXRhW7R4sxeBLItIamAA0Cr73B9oAdYEpItJcVffl9YU4jhMDJCTAp58yv8oY2GqWmyBzZ1Rs2WJCeO1a+Ptv+wxtf/5psc+WL4cgRTKlSsGRR0JyMkyebN6bPXtmf47x4y3c/d690KoVLFli/W/fnr5ekyZmgbr0UqhVKzc3Ie+JRqPvDCxX1UQAERkLnA2EC3oFQll2qwJ/BN/PBsaq6m5gpYgsD/r7MQ/G7jhOrPHgg6yreiR/bq4C5E7Qb9wIRxwB27alLxexSAmHHQZt2sB555m3Zps20Ly5afMLF8L559v87513woMPZk5GtWcPDBsGzzwDHTrAu++mnz7YsWP/Q2XxYnj5Zct7cu+91vc110CXLtmv9dq3L3+WCUQj6OsBq8L2k4EuGeo8AHwpItcBlYBTwtr+lKFtvYwnEJErgSsBjjjiiGjG7ThOrJGQAJ99xi9DRsNrUL06TJ0affPJk03I//vfJohDZpQaNXLOINi6NcycCTfcAI8+CtOn22LcUCTsxES44AIb4nXXmZknYz6TihWhYUPb4uPhoovg11/hv/+FN9+E0aNtXH372jgzvnGsXQvt2lm+lLwmr7xuBgBvqOq/ReQ4YLSIHBVtY1UdCYwESw6eR2NyHKc48cADUKMGv7T4J2A5vZ96ClavhnqZ1MPMTJxoD4frrz+w1LAVK5oW3qMHXHWVBcgcNQp27oTLLjMzz4cfmqCOlqOOsogNjz0GY8ZYiJ5774WyZdPb9Y880j7zK9d9NLdjNdAgbL9+UBbOZUAvAFX9UUTKA7WibOs4Tkln1iz4/HN45BHmLy1P7drQv78J+mnT4MILs2+uaoK+Z8+Dz/89cKBp5BdcAGeeaWWdO5upplGjA+uzShWz1191lZl4KlYs2HA90cwJzwKaiUhjESmLTa6Oz1Dnd+BkABFpBZQH1gb1+otIORFpDDQDZubV4B3HiREefNBsLEOHMn8+HH20mTGqVYvOfPPLLzbZ2qtX3gyneXP48Uezsd9zj5lTDlTIhyMClSoVfEy2HJ99qpoiIkOBSZjr5GuqukBEhgMJqjoeuAV4WURuwiZmB6sleF0gIu9hE7cpwLXuceM4TjpmzjRt/tFH2VfpEBYssHDzcXGWHXDatJy7mDjRPk87Le+GVb685RaPBaJ6yQl84idkKLsv7PtCIGImXlV9BHjkIMboOE4sE6bNJyaaaePoo+1Qjx7mzrhqFTRokHUXEydam7p1C2bIxY0i4s7vOE6JZMYMS+h9661QpQq//GLFbdvaZ48e9pmdVr91K3z3Xd6ZbWIRF/SO4xQeDz4INWvC0KGA5fwuVcrcHcEEfo0a2dvpv/7aFi+dfnoBjLeY4oLecZzC4aOPLPxwoM2DCfpmzcwrBUzod+uWvUY/cSJUrgxdu+b/kIsrLugdxylYUlIsyXe/fhYQJtDmwbxnQmabEN27w8qV8NtvmbsKuVWefLL5pjuRcUHvOE7BsWYNnHqqrSC64gr4/ntTx7FYMStW7J+IDRGy00cy3yxdCklJbp/PCRf0juMUDN99Zxr8jz/C66/DyJHpUgMuWGAaekaNvk0bCwoWyXyTH26VsYgLesdxouLjj+HZZw+goapFAuve3YzvP/1k4R8zMH++fWbU6EN2+qlTratwJk6EFi2gceMDGFcJwgW94zg5smEDDBlipvWUlFw03LnTQjfefDOcdZZFBWvXLmLV+fPNihNpBWqPHhZ+OCkpfdfTprnZJhpc0DuOkyOPPAKbNtlipgULomy0cyecc45FAnvySfOyySbB9y+/WBCwSMk6Itnpp0+HXbtc0EeDC3rHcbJl5UqLwHjyybY/Y0YUjXbuhLPPttjBr74Kt92WbYAXVdJi3ESiVSsLORxup//iCzPxd+sW9aWUWFzQO46TLXfdZXFnRo2ySdGffsqhQUjIT5kCr71mKZZy4I8/zDyUcSI2hIiZ+MPt9BMnWlmFCrm5mpKJC3rHcbJk1iwYOxZuucViwnfpkoNGn1HIR5h0jUQo9EFWGj2YUE9ONhfMlSsthZ+bbaIjrxKPOI4TY6jaotVDD7VwvQDHHmuhaTZvjmBu37HDhPxXX5n75KBBUZ8r5HGTlUYP6ePehCaEXdBHhwt6x3Ei8umnNuH54otpEQro0sUeALNmwSmnhFU+CCEPptHXr28ZorKiRQuoU8fMN9u3m3dO8+a5vqwSiZtuHMfJREoK3HGHCdfLL99ffswx9pnOfKNqLpRffQVvvJFOyG/ZAieckHMe1OwmYkOE7PRff22n6tWr4BN4FFeiEvQi0ktElojIchEZFuH4MyIyN9iWisimsGP7wo5lzEzlOE4R5JVXYPFiS7xRpsz+8mrVzAMm3YTsuHGWOOTf/4ZLLknXz8SJtiD29tszL3YKsXcvLFqUs6AHM9/89Zcl13azTfTkaLoRkTjgBaAnkAzMEpHxQbIRAFT1prD61wEdwrrYqart827IjuPkJ1u3wv33mybep0/m4126mFxXBdm7x6R469Zw3XWZ6n7xhX3+9JOZXE46KXN/S5aYsM/OPh+ie3f7LF06cl9OZKLR6DsDy1U1UVX3AGOBs7OpPwB4Jy8G5zhOwfPUU/D33/D005FNI8ceC2vXBqtUX3wRli+3yhmycqemmqA/5xyzrT/8cOTzZRX6IBLNmpkt/4QT9s8bODkTjaCvB6wK208OyjIhIg2BxsDXYcXlRSRBRH4SkXOyaHdlUCdh7dq1UQ7dcZy8ZvVqs8BccAF07hy5Tpcu9vnTlG0wfLhFo4xgR5kzx4JV9u1r66WmToUffsjc3y+/mHmoRYucxycCn31mpiUnevJ6MrY/8EGGBOANVTUeGAiMEJEjMzZS1ZGqGq+q8bVr187jITmOE4H1MyoAACAASURBVA1bt5r2nZoKjz6adb2jjrLYZDNenG1+llmo/hMmWPFpp8FVV1kiqUciZI+eP9/s/uFzAdnRrh00aRLlRTlAdIJ+NRCelrd+UBaJ/mQw26jq6uAzEZhGevu94zhFgF27zDtyzhx4773sBWnp0hDfZic/zStvkc6yMK5PmGBeOoceCpUqWVyzCRPg55/T14vG48Y5OKIR9LOAZiLSWETKYsI8k/eMiLQEqgM/hpVVF5FywfdawPHAwoxtHccpPFJSzFQzdap5R551Vs5tumyaxBxtz+57Hop4fN06c8E844z9Zddea4uswrX6jRtttWs0E7HOgZOjoFfVFGAoMAlYBLynqgtEZLiIhM/J9wfGqqZzomoFJIjIPGAq8Hi4t47jOIVLaqop5ePHW+Cyiy6KotH06XRZNpo9lGPemjoRq3z5pXnlhAv6qlXh+ustiGUoAmY0oQ+cPEBVi9TWqVMndRwn/0lNVb3uOlVQfeihKBvt26caH6/Jh8crqD77bORqF16oWru2VQ9n3TrVSpVUBw60/eeft/MnJx/wZTgBQIJmIVd9ZazjlFAefBD+7//gppvg7rujbPT225CQQL0nrqdevcgBzvbts4VSvXplji1fsyZcc40FSlu2zOzzNWpA3boHfTlONrigd5wSyLPPmqC/9FJzp4wqlMCOHXDnndCpE1x4IcceGzlk8axZsH59erNNODffDGXLwuOP75+I9VAG+YsLescpYXz0Edx4o/m3jxwZpZBVNbU/ORn+8x8oVYouXSAx0RZPhfPFF6bJn3pq5K7q1IErroA334S5c30itiBwQe84JYhff7VwNF26wJgxmRazRmbHDhgwAEaMMIf4E08E9i+cmjkzffUJE+C448wkkxWhhFO7dvlEbEHggt5xSggbNpivfJUqptWXLx9Fo+RkE+zvvWe2lpdeSjvUqZNlngo336xZY/m/Tz89+24bNNifk8Q1+vzH49E7TgkgJQX69ze5PW1alJOfP/4I555rGv348XDmmekOV6pkQjp8QnbiRPvMyj4fzsMPQ9Om+0MfO/mHa/SOUwK4807L0/3ii2ZWyZFRoyxUZKVKJvAzCPkQXbqY6SY11fYnTIDDD4f2UcSrDWWuyuiZ4+Q9rtE7TowzZoyFo7n2WrjsMuD3303lLlPGEsHWrWufoW3KFJtw7dED3n/ffCKz4Nhj4X//s1DDzZrZQqm+fd2Lpqjhgt5xYpiff7YMUSeeCM88ExTed5+FFj7lFAtXOXNmZteZoUNN2OcQaSw0ITtjhrlUbtoUndnGKVhc0DtOamru7Qd791rkxlq18mdMecDff1s0ytq1TTEvUwaLOfDmm5b1+8kn91fevdtSN61ebTOsIQmeAy1aWGiDn36CpUvNiyddLlmnSODWMadk89tvcNhhJp0yhlWMhKq5rLRubRL0xBMtOPrmzfk/1lxy8cUWXGzcOLOHA2asr1oVhmXICFquHDRsCF27Ri3kwZ6PnTubRj9hAhx/vHXvFC1c0DslF1XzC9+xw1budOoEAwfCypWR68+aBd26Qb9+trTz7rvN5HHFFfaw6N/fpF1KSsFeRwR27LDJ15tvho4dg8JvvrEcgHfemb2Tey7p0sVWuM6b52aboooLeqfkMno0TJpk/uErVsBdd5n626KFLR1dt87q/f67hXXs3NlmHf/7X5NqDz8MCxeajfuKK2wSs3dvm9B87bVCvbSlS+051q5dUKAKd9xhY4uQ2/VgOPbY/V43LuiLKFlFOyuszaNXOgXCX3+pVq+u2rVr+hCLycmql1+uWqqU6iGHqF50kWr58qrlyqneeafq5s1Z97l7t+q4caqNG6see2z+X0M2vPOORYX85Zeg4MMPreDVV/P8XH//bV03aGARMZ3CAY9e6TgZuO462L4dXn01/URsvXrw8ss2adm9O7z1lplqli61/HqHHJJ1n2XL2tLTY46xjBqFyKJFdllNm2KmpDvvtHmFSy7J83PVrm0vOwMHultlUcW9bpySx8cfmxvKI49Ay5aR67RuDZ98YkIyqoAwYdSoUeiCfvFiaNw4CHMw8jV7UH3ySe6vJUpmzDDrkFM0iUqjF5FeIrJERJaLyLAIx58RkbnBtlRENoUdGyQiy4JtUF4O3inmbN5swVGiRdVs6VOmmNP2gbBxowVEb9/eImvlxIEIxurVLbBMIUq+xYuDZ9j27fDAA+YOE02OwIPAtfmiS46/YhGJA14AegLJwCwRGa9hKQFV9aaw+tcRJAAXkRrA/UA8oMDsoG3hqjtO4fPNN2bm2LzZ1sx36GBbx4722aiROYLPmmWTnTNn2vcNG/b3cdRR5t7YrZt91omc1i4dt95qnjKff57jYqADpkYNexPYvh0qV86fc2TDvn2mwJ96KhZ4/s8/7Q3GJXGJJRp1pTOwXFUTAURkLHA2WSf5HoAJd4DTgMmquiFoOxnoBbxzMIN2ijnvv29eLEceaas0586FOXPMA2bfPqtToQLs3GnfS5Uyod63rxmDGzUyof/NNxaT5cUXrV6LFrZsv3dvOPlk6yOcKVPMG2bYsDCfw3ygenX73LChUAT9b79Z+N+W9bbC/U/YA/X44wt8HE7RIRpBXw9YFbafDERcUSEiDYHGwNfZtK0Xod2VwJUARxxxRBRDcootzz1nrotdu1pExHB/7p07bRJ0zhxzW2zY0AR7hw4WXCucnj3NHXLvXqv/zTe2vfWWuT9WqGDC/swzTfBXr24ukM2b28MlPwld08aNUAi/58WL7bPlj6/Dtm02ieyUaPJ6ZqY/8IGq7stNI1UdCYwEiI+P9ymdWCQ11TTpp56y0LdjxmTWuCtUMMHeuXP0/ZYpk9Zm13W3sWvzbqrN+wY++ww+/dQ+wcxDf/4J06dnPm8uUTVnnU8+MZleu3aG7c+GtKUilcLNTAVImqD/4GEYMsQmlp0STTSCfjXQIGy/flAWif7AtRnads/Qdlr0w3OKBb/9ZiEM27Qxodu0aXp78J49JnDGjLGJ0Oees3gqecSKFabEv/YabNlSjsGDT+Wuu06l8bPPmp/hZ5/ZitWrroITTjiocyUlWZCwr74yy9PevWbyD1mZjI705l0+KyTPm8WztlJbdlGzRS1LCOs4WTnYhzbsYZCImWTKAvOANhHqtQSSAAkrqwGsBKoH20qgRnbn8wVTxYzt21XbtbMVM6GtenXVnj1V775b9eOPVU85xcoffTSqFTW7d6uOHKk6apTqrFmq27ZlrpOSovrJJ6qnnWZdx8Wp/vOfqldfrVq2rGrp0qpDhqguX571efbsUf3hB9VnnlGdONH2s2LfPtXnn1etVEm1ShXV//43/aVs26a6cqXqzJmqvU/aoYezWvXll3O81jxn+3b9R6XZekLc96pLlhT8+Z1Cg2wWTEW1WhU4A1gKrADuDsqGA33C6jwAPB6h7RBgebBdmtO5XNAXI1JTbeWoiOqnn6rOm2fC7corVdu3N+kLJnXfeCOqLteuVT3xxPTPDVBt1Ej1jDNUb7tN9d57VY84wsrr1lV98EHV1av395GcrHr99baYNS5OddAg1WXL7AHy3XeqDz9sz6GKFdOfo0YNezhMmGB1Qyxbptqtm9U59VTV337L/hqeeGi3guqmB0fk+pYeFKmpqgMGaC3+1itOy2GQTsxx0IK+IDcX9MWI55+3n9Dw4ZGPb99uknXhwqi6mz/fBHq5cqqjR6suXmwr9x96SHXAAHtxKFfOTnnKKaoffaS6d2/W/f3xh+qNN1oEg1KlVCtU2C/U27ZVHTpU9YMPVFetsreDiy6yqAegWq2aPSDuv9/aVa1q0QOiWeI//pNUBdUfL34hquvOM556StdSU0H1P/8p2FM7hY8Leifv+f5709TPPDN9rJgDZNw41cqVVQ8/XHXGjKzrpaSobtiQu77//FP1rrtUb7jBLEnr1mVdd9cuezkZNMiEO6j27m1vCdGybJm1e61bdG8xecKkSaqlSum33e9RsLcSp2SRnaD3EAgxyq+/wnvvmWfiiSdmmw0u96xZA+edZ+6Po0cfVNJPVQseeffdFiV43DgLN5MVcXH73dSjpU4di3YQDeXKmUfmmWfaHHJSkqXIy81ao0aNoKzsYdFf1XI30ANlxQoLkdymDYv73Q3Tso7s4JRMXNDHINOm2RqZLVv2l7VtawtIQ1vt2gfYeUoKXHCB+YhPmADVDlyY7dxpHixvv21y6rXXDtrzMU8pW9bc7nNL6dLQvMIqFq8/NOfKB8u2bZZGCmDcOBa/WJ7y5e0Z7DghPHpljPHhh3DaaaYVL18O331nYdPr1DFBet55lm3ohBMsqkCuGTbMFiaNHBkW7Dx6VGHBAgu/cvTRJuQfecQ+i5KQP1haVf2DRVuzeTXJK665xhaXvfsuNGnC4sW2QPggXrKcWCQrm05hbW6jP3BeeskcYI47TnX9+szHQ+6EjzyiWqeO2ZEHDbJJy6h4911rdO21uRpXaqpNtN57r2rLltaFiHnXfPZZrroqNtx39EdaihTduTP6Ntm5gkbkq6/sZt57b1pRkyaqF1yQy36cmACfjI1tUlNVH3jA/ppnnGHOLjmxZYvqHXeYz3nlyqqPPaZZC6XUVHOPrFTJniLhvoc5jOvll1WbN7exlSql2r276gsv5OLhUkx5p9frCvaAi4YZM+wevf56lCfYvduemk2aqO7Yoar29xMxTyGn5OGCPoZJSVG95hr7S15ySfaLfiKxbJnq2Wdb+yZNzCslnQvhypXmPA6qxx+f3mE9GzZtUj3/fGt27LH2tvHXX7kbW3FmzlUvKai++050Hkn/+Y/dq8MOyz6JVRqPPaYZ3Wvmz7eisWMPcNBOsSY7Qe+WvGLK3r2W7OH88y144223wRtv5D7ybtOm5uny5ZeWpOLcc22CNHXvPgtVcNRR8MMP8MILFiembt0c+0xIsOCQH35oHjXffw9XX235s0sKLZruQ0hl0ZxdUdVPSLBAl2vWROEh9NtvMHy4/bFOPz2tOC3GjXvcOBlwr5viwKZN7Cl/CAk/l0oL0vjddxbuvFQpePppuOWWgztFz56W7/q+++Cxx+CQL97nP3/egJx+ugWSiSIKo6o9G267zSZ/p0+3IJUlkQqHHUIjkli8IDr3poQE+xsccgiMGGGBNps2zaLyjTeav+eIEemKFy2y4gPxFHJiGxf0RZldu0ga9l9u/r9GTJJe7NhXHrDYYYMGWUrTE0/MO025dMouHin/FDtKVWPEn9dRo18r7n3/6KicyDdssLhln3xiiYxefz2PffeLGzVq0IpFLFqa8x9nyxZLFHLJJXYPP/zQ8qOMGxeh8mef2YEnnsj08F282Hz4Y8l7yckjsrLpFNbmNnpj3xeT9Pla92sltmqVuG06lOf0gz6j9O+/o+zg8cdVGzZUffrp6GZnP/tM9cgjVUH3XTBAB12wQ0H1uedybjpxosWeKVPGAoRFEyYg5vn+e72Fp7R82RRNScm+6tSpZlufONH2Q+b3L7/MUHH7dosR0apVxAnxDh1UTz89T0bvFEPwydhiRHKyLjv9Ou3GVAXV0+LX6m9JqebSCOaykh2pqeZ2AaqNG++f4RsxIs07Ix3Ll1sYAzAvjsmTVdViyJxzjhWPHh35VEuX7m/arJlFbnQCFi3Sl7lMQXXFiuyrPvWU3cO1a21/506bGG/TJkMsn3vusYpTp2bqY98+i8lz0015dgVOMcMFfXFg715N+fcIfabcHVqB7Vq1/E597X979mvHe/eaVC1VKmvn89RUC+oCqoMHm0vO9OmqPXpoWqjH55+3gC7bt5v/dbly5l/51FOZtMSdO1VPOskiQH7yyf7yTZtUb73VNPgqVVSffNK6dML46y/9jq4KOa8V6N/fXr7C+egj+5M9/3xQsGSJ+cJeeGHEPpKSrP7//nfQI3eKKS7oizrz5unyNn20K99ZEK0e2yIH0dq6VbVjR/Nn//nn9MdSUy2GL6hecUXmQGNTp6qecIIdr19/f5zfgQOzdZncskW1c2d7HkyZovrKK6qHHmr+2kOGWMAwJwK7d+t6qivYMzQ7mjZV7dcvfVlqqj1kq1dXXbc21cJ1HnJIljd84kT7c06fnkfjd4odLuiLKnv2WIjfMmW0a5kZWq3Sbh39Zmr2Nu4//lBt0MDCPP7+u5Wlplo8XjCn+qyiSaammrTu1s2c27/5Jqphrlun2rq1poX47drVEoI4OVCpkh5acYtedlnWVTZu1LScLBmZP99e4IaevlxzmjAZMcKqRD2H48QcBy3ogV7AEix5yLAs6pwPLAQWAG+Hle8D5gbb+JzOVWIE/dy5NnsGuv7cy1QkNfoVjfPnm3bXtq3ZUUL2+xtuyLeZ0ORkWwD19ts+2Ro1DRpot8MWadeuWVcJRTHINPEa8K9/qcZJiv5at2e2wfevusoSp/jfpuRyUIIeiMMySzVhfyrB1hnqNAPmANWD/UPDjm3L6RzhW8wL+j17LCVS6dJmA/nww7QQMj/8kIt+Jk+2Pg47zBrfeqv/lxc1jj5ar240QatXz/pP88QT9ueLFJtIVXXt3GStxgY9pfHybP+83brZwmWn5JKdoI9mZWxnYLmqJqrqHmAscHaGOlcAL6jqxsBl8++o/TtLEgsXWvLs+++3Ja0LF0Lfvnz5JVStCscck4u+TjnFEnKvWQN33glPPpm7oOlO/lOjBi1LLWPjRvg7i/+IhARo3Bhq1Ih8vNaEN3mQ+5my8kg+/TTrUy1e7CtinayJRtDXA1aF7ScHZeE0B5qLyPci8pOI9Ao7Vl5EEoLycw5yvEWCffugXz+49FILyb5nTxSNPv0UunSBP/6Ajz+GMWOgZk1ULfzAKadYHPNcMWSIrVR69FEX8kWR6tVpte9XwFatRiIhAeLjs2ivCqNG8a+u82nVylY/796dudrGjfa8d0HvZEVexbopjZlvugMDgJdFJJSRoqGqxgMDgREicmTGxiJyZfAwSFi7dm0eDSn/WLQIPvoI3noLeve2+O6DBpks35UxtIkGKZTOPtsChc+evT9RBKaJrVoFp556gIPJbbolp+CoUYNWu+YA++PQhLNhA6xcmY2gnzkTliyhzKUX8cwzll/guecyV/MYN05ORCPoVwMNwvbrB2XhJGMTrXtVdSWwFBP8qOrq4DMRmAZ0yHgCVR2pqvGqGl/7gFMfFRyhhB0//wyff26xpcaPhz59TOgPGWJxaNi5Ey66yEwr/fvDt99C/frp+vryS/s8YEHvFF2qV6f+pl+pXDmyRj97tn126pRF+1GjLNLceedx2mmmVDz0kGnv4YQEfatWeTZyJ8aIRtDPApqJSGMRKQv0B8ZnqDMO0+YRkVqYKSdRRKqLSLmw8uMxz5xizYwZlkGvTRs44wyL67JmDXzxhZl0Xn8dXn9mkwWieecdM62MGRMxCMmkSRaEqlGjgr8OJ5+pUQPZvYuWzVMjCvqEBPvs2DFC2927YexY0yKqVgXgP/8x3eHuu9NXXbzY0h76b8jJihwFvaqmAEOBScAi4D1VXSAiw0WkT1BtErBeRBYCU4HbVHU90ApIEJF5QfnjqlrsBf3MmTZxGp6urWxZ6NXLhHz75tt5/cHf7T9w3DjT6CPY0Hfvtvyup51WcGN3CpDArNay0a4sNfqmTbOwvn36qRnfBw1KK2reHG64wVJCht4GwH5mzZtb4nTHiURUNnpVnaCqzVX1SFV9JCi7T1XHB99VVW9W1daq2lZVxwblPwT77YLPV/PvUgqGHTvgl19sXjUiX3zBpSvu5eeUo5n/xs9mz8mC774zDc3NNjFK4ErTqv5WkpNh69b0hxMScjDb1K1rs/Rh3Hsv1KplAt+8l80s5PZ5Jzs88Ugu+fln87rp3DnCwalToW9fBraZR5kyyuvfNcu2ry+/tEQh3bvny1CdwiZQ1Vsduh5IPyG7bp3lD4k4ERuyA150USY1vWpVS0zy/ffw3nv2VpiY6PZ5J3tc0OeS0ERsJkH/008WiL1JE2p99S59+ghvvZW96+WkSXD88ZZZyIlBQhp99b+A9II+ZHqJKOjfece0iTCzTThDhkC7dpbg5ZdfrKpr9E52uKDPJTNmQMOGGZJ9zJ1rKd3q1IEpU6BWLS691LS2CRMi9/PXX5bRyc02MUyg0R9ZdhWlS6f3vAlNxHbI5IOGmW3i46F164jdxsXBs8+aW+7VV1uZC3onO0q0oF+/3jwe58yJvs3MmRm0+UWLTFpXqQJffQWHHw7YBGudOjY5G4nJk0mr58QogUZfZusGmjbNLOibN09zqNnP/PmmOGShzYfo1g3OO2//m0GLFnk4bifmKDGpBH/80ezrCxfu30LL0itUgLVroVKl7Pv4+29ISoKhQ4OCxESbLCtVyoR8w4ZpdUuXhosvNpe4NWsyp/v78kuoXRvat8+zS3SKGoccYt5WGzbQqpX95kLMng0nnBChzahRNnEzYECO3T/5pK3fOOywnH+7TsmmRGj0779vSaqHDrXVrLt3mzn93/+2f5adO83ikhPp7PPJyXDyybYUdvJkaJZ54vXSS81++tZb6ctTU03Q9+yZ3kXTiTFKlTLzzcaNtGplK1v37LEH/6pVETxuUlJsvcWZZ0aVcLdRIxg5Eu66K19G78QQJUKjf/ll+6f47jvzWAt3ad+717wYxo+3KAXZMXOm2Uc7HrHOpPT69fD119C2bcT6rVqZG+brr8PNN+8/7/z59nbg9vkSQPXqptEfaw/9FSss7AFEmIidNMmeAjmYbcK55JK8G6oTu8S8Prl6tWnrl1wC9eplXrdUpowtdPrsM9O0s2PGDDiqdSqV+p9lNpzPP88mUIlx6aWwYMH+yTew/2dwQV8iqFEjTaMHs9PPnm2/w0wTsaNGmZP86acX+DCd2CbmBf2YMbaw5OKLs67Tp49p2CHTTCRUYeZMpfPmySbx3347CyNrevr3t3Al4ZOyX35pLwHBvK0TywQafWiydNEie+i3aGHz92ls3AiffAIDB9oya8fJQ2Ja0AdRXuna1ZaaZ8Xpp5tJJrt438uWKps2CV1+fw+ef95ikERB1arQt6+5Ru/aZcHOvvvOvW1KDIFGX7kyNGiwX9BnehGcMcMM+FH+rhwnN8S0oJ8zxzwdcrJjVq9uyvn4jKHawph51zgAOl/eDq65JlfjuPRS2LTJwt588439P7vZpoQQaPRgczbffGMpCTJNxCYl2Wd2GonjHCAxLejffNPegs8/P+e6ffrAr7/unyhLx6uvMvOjVVQqvYvWL12X63GcdBIccYSZb7780kw5UVh9nFgg0OhJTaVVK3PWgggafVKSTRi5Pc/JB2JW0O/da2b0Pn2iy81x1ln2mcl88/nncNVVzKh6KvFdyxJXOveZnEqVMkeKyZPN1bNbNxP2TgmgenWb5d+6NW1CtlSpCOsnkpJMG/AQlE4+ELOCftIkWwQVrftZ06b2ap3OfDNjBpx3HruPPoa5O1vQucuB365Bg2zO4I8/3GxTogglg924MS1MQcuWEeIbJSV5QHkn34hZQf/mm+ap1qtXznVDnHWW2VA3b8besfv0gcMPZ/6jn7Fnj2QdmjgKjjzS8pCAT8SWKEKvk8HqWMjCI9cFvZOPxKSg37jRNPOBA83sGS19+tjixImf7oV//tOCz3/2GTOW2yrFiKGJc8Hw4RaEKotYVU4sEqbR164N118Pl1+eoc7OnbZQqnHjAh+eUzKIStCLSC8RWSIiy0VkWBZ1zheRhSKyQETeDisfJCLLgi36JX8HwfvvW5iD3K4aPPZYewv49MHZZrYZNQpatWLmTJsjy5DuNdd06wYvvRQx2ZQTq4Rp9CIWdTLTRHzI48Y1eiefyDEEgojEAS8APbEk4LNEZHx4SkARaQbcCRyvqhtF5NCgvAZwPxAPKDA7aLsx7y9lP2++aVpzxFyc2RAXB72bLWX8j81JueNuSvftC5jM79zZBbRzAIRp9Fnigt7JZ6LR6DsDy1U1UVX3AGOBjFFhrgBeCAlwVQ3iQnIaMFlVNwTHJgO5sJrnnhUrLPvOJZccgGCeMYOzZt3LRmrw/akPAvb/uXTpwZttnBJKmEafJS7onXwmGkFfD1gVtp8clIXTHGguIt+LyE8i0isXbRGRK0UkQUQS1q5dG/3oIzB6tAn4Cy/MZcM1a6BfP06tv4iyZZXxn5ubWyhGzcFMxDolmAoVoFy5nDV696F38pG8mowtDTQDugMDgJdFpFq0jVV1pKrGq2p87dq1D3gQqma2OfnkXNrT9+61LA4bNlBl3GhOOkkYP976mzHDHhw5xC5znMiIpFsdG5GkJMtl4DGrnXwiml/WaqBB2H79oCycZGC8qu5V1ZXAUkzwR9M2z/j+e1vZmuvQrbfeaqmmXn0V2rXjrLMsdviSJRborGXLCJmAHCdaQqtjsyIpyT1unHwlGkE/C2gmIo1FpCzQH8gYFWYcps0jIrUwU04iMAk4VUSqi0h14NSgLF94803LtJNjXKgtW2D6dHOBGDAAnnsObropLatPaJXs+PH7J2Id54CJRqN3+7yTj+TodaOqKSIyFBPQccBrqrpARIYDCao6nv0CfSGwD7hNVdcDiMhD2MMCYLiqZvOLP3B27YL33oN+/SKsOtyxA154AWbNsnyCK1bsP1anjjk2P/lkWlGDBrZE/X//s/DFLuidg6JGDUspFYnt2+1H5oLeyUeiyjClqhOACRnK7gv7rsDNwZax7WvAawc3zJxZvx66d4fBgyMc/OQTuP12+2fq1MnCSXboYFsWE2B9+tgCJ/CJWOcgqV4d5s2LfOy33+zTBb2Tj8RMKsF69SwMcERCGvyCBVCxYlT9nXWWCfpy5bLMFOg40ZGdjd5dK50CIGYEfbYkJprmHqWQB1tsVbeuOUN4wh/noKheHbZuNe+ujDE5XNA7BUDJEPQrV+baq6FUKQulUKFCPo3J4ipA1gAACfxJREFUKTmEVsdu2gQZ3YeTkuy1sU6dAh+WU3IoGY67iYnQpEmum3XtGiGBs+PkluxWx7oPvVMAxP6va88eCznsfspOYZFdvBt3rXQKgNgX9L//bhl+DkCjd5w8ISeN3gW9k8/EvqAPJYF1jd4pLLLS6LdtszRoLuidfCb2BX1ion26Ru8UFllp9O5D7xQQsS/oV640/8i6dQt7JE5JJSToM2r07lrpFBCxL+gTE82rIS6usEfilFRKl4YqVTJr9CFB72ZFJ5+JfUG/cqWbbZzCJ9Lq2KQkKF8eDjusUIbklBxiX9AnJrrG5BQ+kSJYhnzoPUelk8/EtqDfvNn+uVyjdwqbrDR6t887BUBsC3p3rXSKCpE0+pUrXdA7BUJsC3p3rXSKChk1+q1bLba2C3qnAIhtQe8avVNUCGn0qrbvPvROARKVoBeRXiKyRESWi8iwCMcHi8haEZkbbJeHHdsXVp4xBWH+kpgI1art92N2nMKiRg2Lu7Rzp+27a6VTgOQYplhE4oAXgJ5YEvBZIjJeVRdmqPquqg6N0MVOVW1/8EM9ANy10ikqhK+OrVjRF0s5BUo0Gn1nYLmqJqrqHmAscHb+DiuPcNdKp6iQMd5NyIf+0EMLbUhOySEaQV8PCM9snByUZaSfiMwXkQ9EpEFYeXkRSRCRn0TknEgnEJErgzoJa9eujX702ZGaav9MrtE7RYGM8W5CrpXuQ+8UAHk1Gfsp0EhVjwYmA6PCjjVU1XhgIDBCRI7M2FhVR6pqvKrG186YgedA+fNP2L3bNXqnaBBJo3ezjVNARCPoVwPhGnr9oCwNVV2vqruD3VeATmHHVgeficA0oGByNoU8blyjd4oCGTV696F3CpBoBP0soJmINBaRskB/IJ33jIgcHrbbB1gUlFcXkXLB91rA8UDGSdz8IeRD7xq9UxQI1+i3bDGB779Np4DI0etGVVNEZCgwCYgDXlPVBSIyHEhQ1fHA9SLSB0gBNgCDg+atgP+JSCr2UHk8grdO/rBypdk/GzYskNM5TrZUqWIRVDdscB96p8DJUdADqOoEYEKGsvvCvt8J3Bmh3Q9A24Mc44GRmAj16kG5coVyesdJh4iZbzZudNdKp8CJ3ZWxiYlun3eKFqHVsS7onQImdgW9L5ZyihqheDdJSVChAuSVh5nj5EBsCvpdu2D1ap/scooW4Rq9+9A7BUhUNvpiR2iyyzV6pyhRowYsWwb79rnZxilQYlOjd9dKpygSrtH7b9MpQGJTo/fFUk5RJDwmvWv0TgESuxp9+fJQp05hj8Rx9hMeLtsFvVOAxKagX7nSXo19ssspSoRWx4ILeqdAiU1B7z70TlHENXqnkIg9Qa/qceidoklIo69YEWrVKtyxOCWK2BP0oaBRrtE7RY2QRu9mRaeAiT1B7wnBnaJKSKN3s41TwMSeoA/50LtG7xQ1Qhq9C3qngIk9P3pfLOUUVcqXh5tvhr59C3skTgkj9gT9ypU20VWlSmGPxHEy8+9/F/YInBJIVKYbEeklIktEZLmIDItwfLCIrBWRucF2edixQSKyLNgG5eXgI+IeN47jOOnIUaMXkTjgBaAnkAzMEpHxETJFvauqQzO0rQHcD8QDCswO2m7Mk9FHYuVK6NQp53qO4zglhGg0+s7AclVNVNU9wFjg7Cj7Pw2YrKobAuE+Geh1YEONgn37LHKlT8Q6juOkEY2grwesCttPDsoy0k9E5ovIByLSIDdtReRKEUkQkYS1a9dGOfQIrF4Ne/e66cZxHCeMvHKv/BRopKpHY1r7qNw0VtWRqhqvqvG1DybrjrtWOo7jZCIaQb8aaBC2Xz8oS0NV16vq7mD3FaBTtG3zFF8s5TiOk4loBP0soJmINBaRskB/YHx4BRE5PGy3D7Ao+D4JOFVEqotIdeDUoCx/SEyEuDho0CDnuo7jOCWEHL1uVDVFRIZiAjoOeE1VF4jIcCBBVccD14tIHyAF2AAMDtpuEJGHsIcFwHBV3ZAP12GsXGlCvkyZfDuF4zhOcUNUtbDHkI74+HhNSEg4sMZdu0KFCvDVV3k7KMdxnCKOiMxW1fhIx2Ir1o3HoXccx8lE7Aj6HTtgzRqfiHUcx8lA7Aj67dthwAA45pjCHonjOE6RInaCmtWuDW+/XdijcBzHKXLEjkbvOI7jRMQFveM4Tozjgt5xHCfGcUHvOI4T47igdxzHiXFc0DuO48Q4Lugdx3FiHBf0juM4MU6RC2omImuB3w6ii1rAujwaTnHH70V6/H6kx+/HfmLhXjRU1YiZm4qcoD9YRCQhqwhuJQ2/F+nx+5Eevx/7ifV74aYbx3GcGMcFveM4TowTi4J+ZGEPoAjh9yI9fj/S4/djPzF9L2LORu84juOkJxY1esdxHCcMF/SO4zgxTswIehHpJSJLRGS5iAwr7PEUNCLymoj8LSK/hpXVEJHJIrIs+KxemGMsKESkgYhMFZGFIrJARG4Iykvq/SgvIjNFZF5wPx4MyhuLyIzgf+ZdESlb2GMtKEQkTkTmiMhnwX5M34uYEPQiEge8AJwOtAYGiEjrwh1VgfMG0CtD2TDgK1VtBnwV7JcEUoBbVLU1cCxwbfB7KKn3Yzdwkqq2A9oDvUTkWOAJ4BlVbQpsBC4rxDEWNDcAi8L2Y/pexISgBzoDy1U1UVX3AGOBswt5TAWKqk4HNmQoPhsYFXwfBZxToIMqJFT1T1X9Ofi+FfuHrkfJvR+qqtuC3TLBpsBJwAdBeYm5HyJSH+gNvBLsCzF+L2JF0NcDVoXtJwdlJZ3DVPXP4PtfwGGFOZjCQEQaAR2AGZTg+xGYKuYCfwOTgRXAJlVNCaqUpP+ZEcDtQGqwX5MYvxexIuidHFDzoy1RvrQiUhn4ELhRVbeEHytp90NV96lqe6A+9gbcspCHVCiIyJn/3879q8QRxVEc/x52ldgEEVIsbIIEbO2DFjZpJFgFCRjwJdIkTUBIK8kDxE4ECzE+QLawlGCRIk8gQStbq5Pi3hAJ2oWdcOd8qvlX/PjBnLncOzPAle1vXdcyTcOuC/hHLoDHt/bH9VjfXUoa2f4paUQZzfWCpBlKyO/bPqqHe9uP32xfS5oAz4B5ScM6ku3LPbMCbEhaBx4AD4FPNN6LVkb0Z8BSXTmfBV4BJx3X9D84Abbr9jbwpcNapqbOuX4GftjevXWqr/14JGm+bs8BzynrFhPgZb2sF/2w/db22PYiJSe+2t6i8V4082VsfUJ/BAbAnu0PHZc0VZIOgDXK71YvgffAMXAIPKH8+nnT9t8Lts2RtAqcAt/5Mw/7jjJP38d+LFMWGAeUwd2h7R1JTykvLiwA58Br2zfdVTpdktaAN7ZftN6LZoI+IiLu1srUTURE3CNBHxHRuAR9RETjEvQREY1L0EdENC5BHxHRuAR9RETjfgHbBKaESdipvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Métriques\n",
      "Accuracy : 0.7874\n",
      "F1 Score : 0.7920\n",
      "Quadratic weighted Cohen's kappa = 0.8814\n",
      "\n",
      "Confusion matrix:\n",
      "[[218  72   6   3]\n",
      " [ 21 165  15   1]\n",
      " [  8  35 111   8]\n",
      " [  1   6  13 206]]\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80       299\n",
      "           1       0.59      0.82      0.69       202\n",
      "           2       0.77      0.69      0.72       162\n",
      "           3       0.94      0.91      0.93       226\n",
      "\n",
      "    accuracy                           0.79       889\n",
      "   macro avg       0.80      0.79      0.78       889\n",
      "weighted avg       0.81      0.79      0.79       889\n",
      "\n",
      "\n",
      "Accuracy (binary) : 0.8751\n",
      "F1 Score (binary) : 0.8719\n",
      "Quadratic weighted Cohen's kappa (binary) : 0.7080\n",
      "\n",
      "Confusion matrix (binary) :\n",
      "[[218  81]\n",
      " [ 30 560]]\n",
      "\n",
      "Classification report (binary) :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.73      0.80       299\n",
      "        True       0.87      0.95      0.91       590\n",
      "\n",
      "    accuracy                           0.88       889\n",
      "   macro avg       0.88      0.84      0.85       889\n",
      "weighted avg       0.88      0.88      0.87       889\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.7874015748031497,\n",
       " 'acc_binary': 0.875140607424072,\n",
       " 'f1': 0.7919670448265738,\n",
       " 'f1_binary': 0.871906368342412,\n",
       " 'k_binary': 0.7080321558440021,\n",
       " 'kappa': 0.8813708722536508}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Exemple d'entrainement et d'évaluation de modèle\n",
    "## La synthèse des metriques des modèles évalués se trouve dans le notebook \"Comparaison des modèles.ipynb\"\n",
    "\n",
    "eval_model = ModelEvaluation(*getVGG16(), image_small=True,classes=4, augmentation = 2, retrain = True)\n",
    "eval_model.fit(lr = (5e-4, 5e-5))\n",
    "eval_model.score()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Evaluation des modèles v1.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
